{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 4: Merging and Regular Expressions, Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging and regex (17 points total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data on job postings\n",
    "\n",
    "The previous dataset contains a small subset of employers who faced temporary bans due to violations of H-2A program regulations\n",
    "\n",
    "Since most of the bans have expired, we\"re going to see which of those employers posted new H-2A jobs in the first quarter of 2021 \n",
    "\n",
    "Loading the `jobs.csv` data stored in `pset3_inputdata`.\n",
    "\n",
    "Load the `debar_clean` dataset you created in Problem Set 3 (Merging and Regular Expressions, Part 1).  This is not the original `debar` dataset, but the cleaned version you created in Problem Set 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to load the data \n",
    "\n",
    "\n",
    "jobs = pd.read_csv(\"pset4_inputdata/jobs.csv\")\n",
    "debar_clean = pd.read_csv(\"pset4_inputdata/debar_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.2 Try inner join on employer name  (2 points)\n",
    "\n",
    "- Use the `EMPLOYER_NAME` field of the `jobs` dataset\n",
    "- Use the `Name` field of the `debar_clean` dataset \n",
    "\n",
    "A. Use pd.merge with an inner join on those fields to see whether there are any exact matches. \n",
    "\n",
    "B. If there are exact matches, print the row(s) with exact matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches found: 1 rows\n",
      "    EMPLOYER_NAME            Name\n",
      "0  Rafael Barajas  Rafael Barajas\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "\n",
    "# Using pd.merge to find exact matches between 2 datasets.\n",
    "exact_matches = jobs.merge(debar_clean, left_on=\"EMPLOYER_NAME\", right_on=\"Name\", how=\"inner\")\n",
    "\n",
    "# Output\n",
    "if exact_matches.empty:\n",
    "    print(\"No exact matches found.\")\n",
    "else:\n",
    "    print(f\"Exact matches found: {len(exact_matches)} rows\")\n",
    "    print(exact_matches[[\"EMPLOYER_NAME\", \"Name\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Targeted regex (10 points total)\n",
    "\n",
    "You want to see if you can increase the exact match rate with some basic cleaning of each \n",
    "of the employer name fields in each dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Converting to upper (2 points)\n",
    "\n",
    "A. Convert the `EMPLOYER_NAME` and `Name` fields to uppercase using list comprehension rather than df.varname.str.upper() (it\"s fine to do a separate list comprehension line for each of the two columns)\n",
    "\n",
    "B. Print a random sample of 15 values of each result\n",
    "\n",
    "C. Assign the full vector of uppercase names back to the original data, writing over the original `EMPLOYER_NAME` and `Name` columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to upper\n",
    "employer_upper = [name.upper() if pd.notna(name) else name for name in jobs[\"EMPLOYER_NAME\"]]\n",
    "debar_upper = [name.upper() if pd.notna(name) else name for name in debar_clean[\"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample from EMPLOYER_NAME (jobs):\n",
      "['ELMORE TRUCK REPAIR', 'JACKSON CITRUS, INC.', 'TRIPLE B TRUCKING LLC', 'DIONISIO PRODUCE AND FARMS, LLC', 'WESTERN RANGE ASSOCIATION', 'GALLOPS FARM', 'COUSER CATTLE COMPANY ', 'PECC, INC.', 'S. DERRINGER HARVESTING, INC.', 'ERIC THOMAS LLC', 'COASTAL FARM LABOR SERVICES, INC.', \"THE NORTH CAROLINA GROWER'S ASSOCIATION, INC.\", 'J. GUERRA, LLC', 'WESTERN RANGE ASSOCIATION', 'LUCKY AG, INC.']\n",
      "Random sample from Name (debar_clean):\n",
      "['YOLANDA CHAVEZ', 'STAHLMAN APIARIES, INC', 'YOLANDA CHAVEZ FARMING', 'JOHN & NETA LEOPKY FARMS', 'OMEGA LAMB, LLC', 'J&J HARVESTING', 'OLSON FARMS', 'FIRST AMERICAN HOLDING', 'XAVIER HORNE', 'AVOYELLES HONEY CO., LLC', 'LEONARD SMITH FARMS', 'CISCO PRODUCE INC.', 'VERN STRATTON FARMS', 'MONICA SAAVEDRA (AGENT)', 'SRT FARMS']\n"
     ]
    }
   ],
   "source": [
    "## insert your code for the random sample\n",
    "print(\"Random sample from EMPLOYER_NAME (jobs):\")\n",
    "print(random.sample(employer_upper, 15))\n",
    "\n",
    "print(\"Random sample from Name (debar_clean):\")\n",
    "print(random.sample(debar_upper, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    FAZIO FARMS OPERATING COMPANY, LLC\n",
      "1                    CHARLIE SUNDERLAND\n",
      "2                     MICHAEL RUDEBUSCH\n",
      "3                          LODAHL FARMS\n",
      "4               DUNSON HARVESTING, INC.\n",
      "Name: EMPLOYER_NAME, dtype: object\n",
      "0     AUTUMN HILL ORCHARD\n",
      "1        DOVE CREEK FARMS\n",
      "2               F&W FARMS\n",
      "3    MACKY AND BRAD FARMS\n",
      "4             MARK DUNCAN\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## insert your code for assigning the uppercase names back to the data\n",
    "jobs[\"EMPLOYER_NAME\"] = employer_upper\n",
    "debar_clean[\"Name\"] = debar_upper\n",
    "\n",
    "# Show head to confirm changes\n",
    "print(jobs[\"EMPLOYER_NAME\"].head())\n",
    "print(debar_clean[\"Name\"].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Cleaning up punctuation (4 points)\n",
    "\n",
    "You notice that INC, CO, and LLC are sometimes followed by a period (.) but sometimes not\n",
    "\n",
    "A. For each dataset, write a regex pattern using `re.sub` to remove the . but only if it\"s preceded by INC, LLC, or CO \n",
    "\n",
    "Make sure LLC, INC, CO remain part of the string but just without the dot\n",
    "\n",
    "B. Test the pattern on the positive and negative example we provide below and print the result. See the Github issue for examples of what to return\n",
    "\n",
    "\n",
    "**Hint**: https://stackoverflow.com/questions/7191209/python-re-sub-replace-with-matched-content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example_1 = \"CISCO PRODUCE INC.\"\n",
    "pos_example_2 = \"AVOYELLES HONEY CO., LLC\"\n",
    "neg_example = \"E.V. RANCH LLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          CISCO PRODUCE INC\n",
      "1    AVOYELLES HONEY CO, LLC\n",
      "2             E.V. RANCH LLP\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## insert your code here with the regex pattern for part A\n",
    "pattern = r\"\\b(INC|LLC|CO)\\.\"\n",
    "\n",
    "def clean_names(name):\n",
    "    return re.sub(pattern, r\"\\1\", name) if pd.notna(name) else name\n",
    "\n",
    "example_series = pd.Series([pos_example_1, pos_example_2, neg_example])\n",
    "cleaned = example_series.apply(clean_names)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 (4 points)\n",
    "\n",
    "Use that pattern in conjunction with `re.sub` and list comprehension to clean the employer name columns in each dataset. Save the new columns as `name_clean` in each. Then, use row subsetting to (1) subset to rows that changed names and (2) for:\n",
    "\n",
    "- `debar_clean` print the `Name` and `name_clean` columns\n",
    "- `jobs` print the `EMPLOYER_NAME` and `name_clean` columns\n",
    "\n",
    "Make sure to use the uppercase versions of the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to clean the columns\n",
    "debar_clean[\"name_clean\"] = debar_clean[\"Name\"].apply(clean_names)\n",
    "jobs[\"name_clean\"] = jobs[\"EMPLOYER_NAME\"].apply(clean_names)\n",
    "\n",
    "# Subset to rows where the cleaned name is different from the original\n",
    "debar_changed = debar_clean[debar_clean[\"Name\"] != debar_clean[\"name_clean\"]]\n",
    "jobs_changed = jobs[jobs[\"EMPLOYER_NAME\"] != jobs[\"name_clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debar_clean: rows with changed names\n",
      "                        Name               name_clean\n",
      "14  ALTENDORF TRANSPORT INC.  ALTENDORF TRANSPORT INC\n",
      "18     ANTON FERTILIZER INC.     ANTON FERTILIZER INC\n",
      "19  AVOYELLES HONEY CO., LLC  AVOYELLES HONEY CO, LLC\n",
      "26        CISCO PRODUCE INC.        CISCO PRODUCE INC\n",
      "27        CISCO PRODUCE INC.        CISCO PRODUCE INC\n",
      "jobs: rows with changed names\n",
      "                               EMPLOYER_NAME  \\\n",
      "4                    DUNSON HARVESTING, INC.   \n",
      "7   FARM LABOR ASSOCIATION FOR GROWERS, INC.   \n",
      "14                        MCLAIN FARMS, INC.   \n",
      "17                       BONNIE PLANTS, INC.   \n",
      "18               B & W QUALITY GROWERS, INC.   \n",
      "\n",
      "                                 name_clean  \n",
      "4                    DUNSON HARVESTING, INC  \n",
      "7   FARM LABOR ASSOCIATION FOR GROWERS, INC  \n",
      "14                        MCLAIN FARMS, INC  \n",
      "17                       BONNIE PLANTS, INC  \n",
      "18               B & W QUALITY GROWERS, INC  \n"
     ]
    }
   ],
   "source": [
    "## your code here to print the head\n",
    "print(\"debar_clean: rows with changed names\")\n",
    "print(debar_changed[[\"Name\", \"name_clean\"]].head())\n",
    "\n",
    "print(\"jobs: rows with changed names\")\n",
    "print(jobs_changed[[\"EMPLOYER_NAME\", \"name_clean\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 More joins and more cleaning (5 points)\n",
    "\n",
    "A. Conduct another inner join between `jobs` and `debar_clean` now using the `name_clean` column; print the result. Did the cleaning result in any more employers matched between the two datasets?\n",
    "\n",
    "B. Create a new column in `debar_clean` called `name_clean_2` that uses regex to take the following name in that dataset:\n",
    "\n",
    "- `SLASH E.V. RANCH LLP` in the `debar_clean` dataset\n",
    "\n",
    "And cleans it up so that it matches with this employer in `jobs`\n",
    "\n",
    "- `SLASH EV RANCH` in the `jobs` dataset\n",
    "\n",
    "Eg a pattern to remove the dots in the EV and the space+LLP-- you can apply the pattern to all employer names in debar_clean (so don\"t need to worry about only applying it to that one employer)\n",
    "\n",
    "\n",
    "C. Conduct a left join using `name_clean_2` as the join column where the left hand dataframe is `jobs`; right hand dataframe is `debar_clean`, store the result as a dataframe, and print the rows where the merge indicator indicates the row was found in both dataframe\n",
    "\n",
    "**Note**: this manual cleaning process is inefficient and helps motivate why talked about fuzzy matching. Fuzzy matching could recognize that Slash EV ranch is a highly similar string to slash ev ranch llp and match them without us needing to use regex to make the strings identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found after cleaning: 1 rows\n",
      "No Changes Found\n",
      "    EMPLOYER_NAME            Name      name_clean\n",
      "0  RAFAEL BARAJAS  RAFAEL BARAJAS  RAFAEL BARAJAS\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "\n",
    "# Part A: Find matches after cleaning\n",
    "clean_matches = jobs.merge(debar_clean, left_on=\"name_clean\", right_on=\"name_clean\", how=\"inner\")\n",
    "\n",
    "if clean_matches.empty:\n",
    "    print(\"No matches found after cleaning.\")\n",
    "else:\n",
    "    print(f\"Matches found after cleaning: {len(clean_matches)} rows\")\n",
    "    print(\"No Changes Found\" if len(exact_matches) == len(clean_matches) else \"Changes found after cleaning.\")\n",
    "    print(clean_matches[[\"EMPLOYER_NAME\", \"Name\", \"name_clean\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name    name_clean_2\n",
      "90  SLASH E.V. RANCH LLP  SLASH EV RANCH\n",
      "       EMPLOYER_NAME    name_clean_2\n",
      "1115  SLASH EV RANCH  SLASH EV RANCH\n"
     ]
    }
   ],
   "source": [
    "# Part B: Remove dots in EV and space in EV\n",
    "def clean_ev_llp(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    name = re.sub(r\"\\b([A-Z])\\.\", r\"\\1\", name)\n",
    "    name = re.sub(r\"\\sLLP\\b\", \"\", name)\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "debar_clean['name_clean_2'] = debar_clean['Name'].apply(clean_ev_llp)\n",
    "jobs['name_clean_2'] = jobs['EMPLOYER_NAME'].apply(clean_ev_llp)\n",
    "\n",
    "print(debar_clean[debar_clean['Name'].str.contains('SLASH')][['Name', 'name_clean_2']])\n",
    "print(jobs[jobs['EMPLOYER_NAME'].str.contains('SLASH')][['EMPLOYER_NAME', 'name_clean_2']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EMPLOYER_NAME                  Name    name_clean_2 _merge\n",
      "791   RAFAEL BARAJAS        RAFAEL BARAJAS  RAFAEL BARAJAS   both\n",
      "1115  SLASH EV RANCH  SLASH E.V. RANCH LLP  SLASH EV RANCH   both\n"
     ]
    }
   ],
   "source": [
    "# Part C: Merge datasets using the new cleaned column\n",
    "merged = jobs.merge(debar_clean, left_on=\"name_clean_2\", right_on=\"name_clean_2\", how=\"left\", indicator=True)\n",
    "\n",
    "print(merged[merged['_merge'] == 'both'][[\"EMPLOYER_NAME\", \"Name\", \"name_clean_2\", \"_merge\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optional extra credit 1: regex to separate companies from individuals (1 point)\n",
    "\n",
    "You notice some employers in `debar_clean` have both the name of the company and the name of individual, e.g.:\n",
    "    \n",
    "COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\n",
    "\n",
    "Use the uppercase/cleaned `name_clean` in `debar_clean`\n",
    "\n",
    "A. Write a regex pattern that does the following:\n",
    "    - Captures the pattern that occurs before COMPANY if (COMPANY) is in string; so in example above, extracts COUNTY FAIR FARM \n",
    "    - Captures the pattern that occurs before INDIVIDUAL if (INDIVIDUAL) is also in string -- so in above, extracts ANDREW WILLIAMSON (so omit the \"and\")\n",
    "    \n",
    "B. Test the pattern on `pos_example` and `neg_example`-- make sure former returns a list (if using find.all) or match object (if using re.search) with the company name and individual name separated out; make sure latter returns empty\n",
    "    \n",
    "**Hints and resources**: for step A, you can either use re.search, re.match, or re.findall; don\"t worry about matching B&R Harvesting and Paul Cruz (Individual)\n",
    "\n",
    "- Same regex resources as above\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS match: ('COUNTY FAIR FARM', 'ANDREW WILLIAMSON')\n",
      "NEG match: No match\n"
     ]
    }
   ],
   "source": [
    "pos_example = \"COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\"\n",
    "neg_example = \"CISCO PRODUCE INC\"\n",
    "\n",
    "## your code here to define the pattern\n",
    "# (?P<co>.+?) = capture group for company name (non-greedy)\n",
    "# (?P<ind>.+?) = capture group for individual name (non-greedy)\n",
    "# \\s* = optional space (also handles extra spaces)\n",
    "# \\s+AND\\s+ = \" AND \" with optional space around it\n",
    "# \\(COMPANY\\) = literal string \"(COMPANY)\"\n",
    "# \\(INDIVIDUAL\\) = literal string \"(INDIVIDUAL)\"\n",
    "pattern = r\"^(?P<co>.+?)\\s*\\(COMPANY\\)\\s+AND\\s+(?P<ind>.+?)\\s*\\(INDIVIDUAL\\)\"\n",
    "\n",
    "## your code here to apply it to the pos_example\n",
    "pos_match = re.match(pattern, pos_example)\n",
    "print(\"POS match:\", pos_match.groups() if pos_match else \"No match\")\n",
    "\n",
    "## your code here to apply it to the negative example\n",
    "pos_match_neg = re.match(pattern, neg_example)\n",
    "print(\"NEG match:\", pos_match_neg.groups() if pos_match_neg else \"No match\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Iterate over the `name_clean` column in debar and use regex to create two new columns in `debar_clean`:\n",
    "   - `co_name`: A column for company (full `name_clean` string if no match; pattern before COMPANY if one extracted)\n",
    "   - `ind_name`: A column for individual (full `name_clean` string if no match; pattern before INDIVIDUAL if one extracted)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            name_clean  \\\n",
      "3                                 MACKY AND BRAD FARMS   \n",
      "16                             ANNABELLA LAND & CATTLE   \n",
      "17                             ANNABELLA LAND & CATTLE   \n",
      "20         B & R HARVESTING AND PAUL CRUZ (INDIVIDUAL)   \n",
      "28                       CITY PINESTRAW AND HARVESTING   \n",
      "29   COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMS...   \n",
      "44                                  GONZALO FERNANDEZ*   \n",
      "51                                     JEREMY CHANDLER   \n",
      "53                JIM AND ANN SHIPLEY WILLIAM SHIPLEY*   \n",
      "59                                LANDMARK LANDSCAPING   \n",
      "93                            TRAVIS AND TARA LAMBOURN   \n",
      "103                                     YOLANDA CHAVEZ   \n",
      "104                             YOLANDA CHAVEZ FARMING   \n",
      "\n",
      "                                         co_name  \\\n",
      "3                           MACKY AND BRAD FARMS   \n",
      "16                       ANNABELLA LAND & CATTLE   \n",
      "17                       ANNABELLA LAND & CATTLE   \n",
      "20   B & R HARVESTING AND PAUL CRUZ (INDIVIDUAL)   \n",
      "28                 CITY PINESTRAW AND HARVESTING   \n",
      "29                              COUNTY FAIR FARM   \n",
      "44                            GONZALO FERNANDEZ*   \n",
      "51                               JEREMY CHANDLER   \n",
      "53          JIM AND ANN SHIPLEY WILLIAM SHIPLEY*   \n",
      "59                          LANDMARK LANDSCAPING   \n",
      "93                      TRAVIS AND TARA LAMBOURN   \n",
      "103                               YOLANDA CHAVEZ   \n",
      "104                       YOLANDA CHAVEZ FARMING   \n",
      "\n",
      "                                        ind_name  \n",
      "3                           MACKY AND BRAD FARMS  \n",
      "16                       ANNABELLA LAND & CATTLE  \n",
      "17                       ANNABELLA LAND & CATTLE  \n",
      "20   B & R HARVESTING AND PAUL CRUZ (INDIVIDUAL)  \n",
      "28                 CITY PINESTRAW AND HARVESTING  \n",
      "29                             ANDREW WILLIAMSON  \n",
      "44                            GONZALO FERNANDEZ*  \n",
      "51                               JEREMY CHANDLER  \n",
      "53          JIM AND ANN SHIPLEY WILLIAM SHIPLEY*  \n",
      "59                          LANDMARK LANDSCAPING  \n",
      "93                      TRAVIS AND TARA LAMBOURN  \n",
      "103                               YOLANDA CHAVEZ  \n",
      "104                       YOLANDA CHAVEZ FARMING  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "co_list = []\n",
    "ind_list = []\n",
    "\n",
    "for name in debar_clean[\"name_clean\"]:\n",
    "    match = re.match(pattern, name)\n",
    "    if match:\n",
    "        co = match.group(\"co\").strip()\n",
    "        ind = match.group(\"ind\").strip()\n",
    "        co_list.append(co)\n",
    "        ind_list.append(ind)\n",
    "    else:\n",
    "        co_list.append(name)\n",
    "        ind_list.append(name)\n",
    "\n",
    "debar_clean[\"co_name\"] = co_list\n",
    "debar_clean[\"ind_name\"] = ind_list\n",
    "\n",
    "print(debar_clean[debar_clean[\"name_clean\"].str.contains(\"AND\")][[\"name_clean\", \"co_name\", \"ind_name\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "D. Print three columns for the rows in `debar_clean` containing the negative example and positive example described above (county fair farm and cisco produce):\n",
    "\n",
    "- `name_clean`\n",
    "- `co_name`\n",
    "- `ind_name`\n",
    "- `Violation`\n",
    "\n",
    "**Note**: as shown in the outcome there may be duplicates of the same company reflecting different violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTY FAIR FARM rows:\n",
      "                                           name_clean           co_name  \\\n",
      "29  COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMS...  COUNTY FAIR FARM   \n",
      "\n",
      "             ind_name      Violation  \n",
      "29  ANDREW WILLIAMSON  WHD Debarment  \n",
      "\n",
      "CISCO PRODUCE rows:\n",
      "           name_clean            co_name           ind_name  \\\n",
      "26  CISCO PRODUCE INC  CISCO PRODUCE INC  CISCO PRODUCE INC   \n",
      "27  CISCO PRODUCE INC  CISCO PRODUCE INC  CISCO PRODUCE INC   \n",
      "\n",
      "                                     Violation  \n",
      "26   Failure to respond to audit (no response)  \n",
      "27  Impeding the Audit Process â€“ Non- Response  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "mask_county = debar_clean[\"name_clean\"].str.contains(\"COUNTY FAIR FARM\")\n",
    "mask_cisco  = debar_clean[\"name_clean\"].str.contains(\"CISCO PRODUCE\")\n",
    "\n",
    "cols = [\"name_clean\", \"co_name\", \"ind_name\", \"Violation\"]\n",
    "\n",
    "print(\"COUNTY FAIR FARM rows:\")\n",
    "print(debar_clean.loc[mask_county, cols])\n",
    "\n",
    "print(\"\\nCISCO PRODUCE rows:\")\n",
    "print(debar_clean.loc[mask_cisco, cols])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
