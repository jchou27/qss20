{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1: Analysis of racial disparities in felony sentencing, Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Load packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "## can add others if you need them\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1: Load the data (0 points)\n",
    "\n",
    "Load the data from `sentencing_asof0405.csv`\n",
    "- *Notes*: You may receive a warning about mixed data types upon import; feel free to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharp\\AppData\\Local\\Temp\\ipykernel_28012\\2150987340.py:1: DtypeWarning: Columns (10,11,14,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"pset1_inputdata/sentencing_asof0405.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pset1_inputdata/sentencing_asof0405.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2: Print head, dimensions, info (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>CASE_PARTICIPANT_ID</th>\n",
       "      <th>RECEIVED_DATE</th>\n",
       "      <th>OFFENSE_CATEGORY</th>\n",
       "      <th>PRIMARY_CHARGE_FLAG</th>\n",
       "      <th>CHARGE_ID</th>\n",
       "      <th>CHARGE_VERSION_ID</th>\n",
       "      <th>DISPOSITION_CHARGED_OFFENSE_TITLE</th>\n",
       "      <th>CHARGE_COUNT</th>\n",
       "      <th>DISPOSITION_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>INCIDENT_CITY</th>\n",
       "      <th>INCIDENT_BEGIN_DATE</th>\n",
       "      <th>INCIDENT_END_DATE</th>\n",
       "      <th>LAW_ENFORCEMENT_AGENCY</th>\n",
       "      <th>LAW_ENFORCEMENT_UNIT</th>\n",
       "      <th>ARREST_DATE</th>\n",
       "      <th>FELONY_REVIEW_DATE</th>\n",
       "      <th>FELONY_REVIEW_RESULT</th>\n",
       "      <th>ARRAIGNMENT_DATE</th>\n",
       "      <th>UPDATED_OFFENSE_CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50510112469</td>\n",
       "      <td>116304211997</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>2</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50510213021</td>\n",
       "      <td>98265074680</td>\n",
       "      <td>HOME INVASION</td>\n",
       "      <td>14</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516447217</td>\n",
       "      <td>131972895911</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>4</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516497493</td>\n",
       "      <td>131966356472</td>\n",
       "      <td>FIRST DEGREE MURDER</td>\n",
       "      <td>5</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149765331439</td>\n",
       "      <td>175691153649</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>PROMIS Conversion</td>\n",
       "      <td>False</td>\n",
       "      <td>50516648320</td>\n",
       "      <td>98059642859</td>\n",
       "      <td>HOME INVASION</td>\n",
       "      <td>13</td>\n",
       "      <td>12/17/2014 12:00:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/9/1984 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO POLICE DEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/1984 12:00:00 AM</td>\n",
       "      <td>08/15/1984 12:00:00 AM</td>\n",
       "      <td>Charge(S) Approved</td>\n",
       "      <td>9/21/1984 12:00:00 AM</td>\n",
       "      <td>Homicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CASE_ID  CASE_PARTICIPANT_ID          RECEIVED_DATE  \\\n",
       "0  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "1  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "2  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "3  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "4  149765331439         175691153649  8/15/1984 12:00:00 AM   \n",
       "\n",
       "    OFFENSE_CATEGORY  PRIMARY_CHARGE_FLAG    CHARGE_ID  CHARGE_VERSION_ID  \\\n",
       "0  PROMIS Conversion                False  50510112469       116304211997   \n",
       "1  PROMIS Conversion                False  50510213021        98265074680   \n",
       "2  PROMIS Conversion                False  50516447217       131972895911   \n",
       "3  PROMIS Conversion                False  50516497493       131966356472   \n",
       "4  PROMIS Conversion                False  50516648320        98059642859   \n",
       "\n",
       "  DISPOSITION_CHARGED_OFFENSE_TITLE  CHARGE_COUNT        DISPOSITION_DATE  \\\n",
       "0               FIRST DEGREE MURDER             2  12/17/2014 12:00:00 AM   \n",
       "1                     HOME INVASION            14  12/17/2014 12:00:00 AM   \n",
       "2               FIRST DEGREE MURDER             4  12/17/2014 12:00:00 AM   \n",
       "3               FIRST DEGREE MURDER             5  12/17/2014 12:00:00 AM   \n",
       "4                     HOME INVASION            13  12/17/2014 12:00:00 AM   \n",
       "\n",
       "   ... INCIDENT_CITY   INCIDENT_BEGIN_DATE INCIDENT_END_DATE  \\\n",
       "0  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "1  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "2  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "3  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "4  ...           NaN  8/9/1984 12:00:00 AM               NaN   \n",
       "\n",
       "  LAW_ENFORCEMENT_AGENCY LAW_ENFORCEMENT_UNIT            ARREST_DATE  \\\n",
       "0    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "1    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "2    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "3    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "4    CHICAGO POLICE DEPT                  NaN  8/15/1984 12:00:00 AM   \n",
       "\n",
       "       FELONY_REVIEW_DATE FELONY_REVIEW_RESULT       ARRAIGNMENT_DATE  \\\n",
       "0  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "1  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "2  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "3  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "4  08/15/1984 12:00:00 AM   Charge(S) Approved  9/21/1984 12:00:00 AM   \n",
       "\n",
       "  UPDATED_OFFENSE_CATEGORY  \n",
       "0                 Homicide  \n",
       "1                 Homicide  \n",
       "2                 Homicide  \n",
       "3                 Homicide  \n",
       "4                 Homicide  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(248146, 41)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248146 entries, 0 to 248145\n",
      "Data columns (total 41 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   CASE_ID                            248146 non-null  int64  \n",
      " 1   CASE_PARTICIPANT_ID                248146 non-null  int64  \n",
      " 2   RECEIVED_DATE                      248146 non-null  object \n",
      " 3   OFFENSE_CATEGORY                   248146 non-null  object \n",
      " 4   PRIMARY_CHARGE_FLAG                248146 non-null  bool   \n",
      " 5   CHARGE_ID                          248146 non-null  int64  \n",
      " 6   CHARGE_VERSION_ID                  248146 non-null  int64  \n",
      " 7   DISPOSITION_CHARGED_OFFENSE_TITLE  248146 non-null  object \n",
      " 8   CHARGE_COUNT                       248146 non-null  int64  \n",
      " 9   DISPOSITION_DATE                   248146 non-null  object \n",
      " 10  DISPOSITION_CHARGED_CHAPTER        248146 non-null  object \n",
      " 11  DISPOSITION_CHARGED_ACT            242771 non-null  object \n",
      " 12  DISPOSITION_CHARGED_SECTION        242771 non-null  object \n",
      " 13  DISPOSITION_CHARGED_CLASS          248127 non-null  object \n",
      " 14  DISPOSITION_CHARGED_AOIC           248122 non-null  object \n",
      " 15  CHARGE_DISPOSITION                 248146 non-null  object \n",
      " 16  CHARGE_DISPOSITION_REASON          904 non-null     object \n",
      " 17  SENTENCE_JUDGE                     247404 non-null  object \n",
      " 18  SENTENCE_COURT_NAME                246761 non-null  object \n",
      " 19  SENTENCE_COURT_FACILITY            246216 non-null  object \n",
      " 20  SENTENCE_PHASE                     248146 non-null  object \n",
      " 21  SENTENCE_DATE                      248146 non-null  object \n",
      " 22  SENTENCE_TYPE                      248146 non-null  object \n",
      " 23  CURRENT_SENTENCE_FLAG              248146 non-null  bool   \n",
      " 24  COMMITMENT_TYPE                    246464 non-null  object \n",
      " 25  COMMITMENT_TERM                    246434 non-null  object \n",
      " 26  COMMITMENT_UNIT                    246434 non-null  object \n",
      " 27  LENGTH_OF_CASE_in_Days             229126 non-null  float64\n",
      " 28  AGE_AT_INCIDENT                    238359 non-null  float64\n",
      " 29  RACE                               246879 non-null  object \n",
      " 30  GENDER                             247337 non-null  object \n",
      " 31  INCIDENT_CITY                      228745 non-null  object \n",
      " 32  INCIDENT_BEGIN_DATE                239122 non-null  object \n",
      " 33  INCIDENT_END_DATE                  22008 non-null   object \n",
      " 34  LAW_ENFORCEMENT_AGENCY             239405 non-null  object \n",
      " 35  LAW_ENFORCEMENT_UNIT               76408 non-null   object \n",
      " 36  ARREST_DATE                        242981 non-null  object \n",
      " 37  FELONY_REVIEW_DATE                 171907 non-null  object \n",
      " 38  FELONY_REVIEW_RESULT               171907 non-null  object \n",
      " 39  ARRAIGNMENT_DATE                   229126 non-null  object \n",
      " 40  UPDATED_OFFENSE_CATEGORY           248146 non-null  object \n",
      "dtypes: bool(2), float64(2), int64(5), object(32)\n",
      "memory usage: 74.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: data cleaning/interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Understanding the unit of analysis (5 points)\n",
    "\n",
    "- Print the number of unique values for the following columns. Do so in a way that avoids copying/pasting code for \n",
    "the three:\n",
    "\n",
    "    - Cases (`CASE_ID`)\n",
    "    - People in that case (`CASE_PARTICIPANT_ID`)\n",
    "    - Charges (`CHARGE_ID`)\n",
    "\n",
    "- Write a couple sentences on the following and show an example of each (e.g., a case involving multiple people):\n",
    "    \n",
    "    - Why there are more unique people than unique cases?\n",
    "    - Why there are more unique charges than unique people?\n",
    "\n",
    "- Print the mean and median number of charges per case\n",
    "\n",
    "- Print the mean and median number of participants per case\n",
    "\n",
    "- Does the data seem to enable us to follow the same defendant across different cases they're charged in? Write 1 sentence in support of your conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE_ID                197519\n",
      "CASE_PARTICIPANT_ID    211977\n",
      "CHARGE_ID              229015\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# No. of unique values in CASE_ID, CASE_PARTICIPANT_ID, CHARGE_ID, in a way that avoids coping/pasting code for the three\n",
    "unique_counts = df[[\"CASE_ID\",\"CASE_PARTICIPANT_ID\",\"CHARGE_ID\"]].nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more unique people than unique cases because each unique cases can be committed by one or more unique person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE: CASE_ID 166402790922 has participants: [144234439761 144234534133]\n"
     ]
    }
   ],
   "source": [
    "# Find a case with multiple participants\n",
    "participants_counts = df.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "multi_participants_ex = participants_counts[participants_counts > 1].index[0]\n",
    "\n",
    "# Show the participants for that case\n",
    "participants = df[df[\"CASE_ID\"] == multi_participants_ex][\"CASE_PARTICIPANT_ID\"].unique()\n",
    "print(f\"EXAMPLE: CASE_ID {multi_participants_ex} has participants: {participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more unique charges than unique people becuase one person can be charged with multiple counts of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE: CASE_PARTICIPANT_ID 97581722610 has charges: ['INT HOMI OF UNBORN CHILD=38-9-1.2' 'MURDER=720-5\\\\9-1(A)(1-3)'\n",
      " 'ARMED ROBBERY=720-5\\\\18-2(A)']\n"
     ]
    }
   ],
   "source": [
    "# Find participants with more than one unique charge\n",
    "participant_charge_counts = df.groupby(\"CASE_PARTICIPANT_ID\")[\"CHARGE_ID\"].nunique()\n",
    "multi_charge_participant = participant_charge_counts[participant_charge_counts > 1].index[0]\n",
    "\n",
    "# Show the charges for that participant\n",
    "charges = df[df[\"CASE_PARTICIPANT_ID\"] == multi_charge_participant][\"DISPOSITION_CHARGED_OFFENSE_TITLE\"].unique()\n",
    "print(f\"EXAMPLE: CASE_PARTICIPANT_ID {multi_charge_participant} has charges: {charges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of charges per case: 1.1594580774507768\n",
      "Median number of charges per case: 1.0\n",
      "Mean number of participants per case: 1.0731980214561636\n",
      "Median number of participants per case: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Mean and median number of charges per case\n",
    "charges_per_case = df.groupby(\"CASE_ID\")[\"CHARGE_ID\"].nunique()\n",
    "print(\"Mean number of charges per case:\", charges_per_case.mean())\n",
    "print(\"Median number of charges per case:\", charges_per_case.median())\n",
    "\n",
    "# Mean and median number of participants per case\n",
    "participants_per_case = df.groupby(\"CASE_ID\")[\"CASE_PARTICIPANT_ID\"].nunique()\n",
    "print(\"Mean number of participants per case:\", participants_per_case.mean())\n",
    "print(\"Median number of participants per case:\", participants_per_case.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data does NOT seem to enable us to follow the same defendant across different cases because `CASE_PARTICIPANT_ID` is unique to each case-participant combination, not to each defendant. There is no persistent defendant ID across different cases in the visible columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1: Which offense is final? (3 points)\n",
    "\n",
    "- First, read the data documentation [link](https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf) and summarize in your own words the differences between `OFFENSE_CATEGORY` and `UPDATED_OFFENSE_CATEGORY` \n",
    "\n",
    "- Construct an indicator `is_changed_offense` that's True for case-participant-charge observations (rows) where there's a difference between the original charge (offense category) and the most current charge (updated offense category). What are some of the more common changed offenses? (can just print result of sort_values based on original offense category)\n",
    "\n",
    "- Print one example of a changed offense from one of these categories and comment on what the reason may be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "OFFENSE_CATEGORY is the case’s initial broad offense label before charges are finalized, while UPDATED_OFFENSE_CATEGORY is the later, revised label recalculated to match the case’s primary/most severe charge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with changed offense: 35865\n",
      "\n",
      "Most common changed offenses (by original offense category):\n",
      "                OFFENSE_CATEGORY  count\n",
      "61             PROMIS Conversion   6394\n",
      "33                           DUI   3896\n",
      "81  UUW - Unlawful Use of Weapon   2155\n",
      "60                 Other Offense   2125\n",
      "2             Aggravated Battery   1927\n",
      "..                           ...    ...\n",
      "63                       Perjury      4\n",
      "70                  Prostitution      3\n",
      "22       Benefit Recipient Fraud      2\n",
      "29    Compelling Gang Membership      2\n",
      "85             Violate Bail Bond      2\n",
      "\n",
      "[88 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create indicator for changed offense (True if original differs from updated)\n",
    "is_changed_offense = df[\"OFFENSE_CATEGORY\"].fillna(\"\") != df[\"UPDATED_OFFENSE_CATEGORY\"].fillna(\"\")\n",
    "\n",
    "# Add to datafram\n",
    "df[\"is_changed_offense\"] = is_changed_offense\n",
    "\n",
    "# Count the charged offenses based on original offense category\n",
    "charged_offenses_sorted = df[df[\"is_changed_offense\"]].groupby(\"OFFENSE_CATEGORY\").size().reset_index(name=\"count\").sort_values(\"count\", ascending=False)\n",
    "print(f\"Total rows with changed offense: {is_changed_offense.sum()}\")\n",
    "print(f\"\\nMost common changed offenses (by original offense category):\")\n",
    "print(charged_offenses_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a changed offense:\n",
      "OFFENSE_CATEGORY UPDATED_OFFENSE_CATEGORY  CASE_PARTICIPANT_ID   CHARGE_ID\n",
      "Attempt Homicide         Domestic Battery         203478864452 89337340966\n"
     ]
    }
   ],
   "source": [
    "# Print one example of a changed offense from a common category\n",
    "common_offcat_example = df[df[\"is_changed_offense\"] & (df[\"OFFENSE_CATEGORY\"] != \"PROMIS Conversion\")][[\"OFFENSE_CATEGORY\", \"UPDATED_OFFENSE_CATEGORY\", \"CASE_PARTICIPANT_ID\", \"CHARGE_ID\"]].head(1)\n",
    "print(\"Example of a changed offense:\")\n",
    "print(common_offcat_example.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change in attempt homicide to domestic battery is based on the intent of the criminal and/or insufficient evidence, where battery is the intent to injury and homicide is intent to kill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2: Simplifying the charges (5 points)\n",
    "\n",
    "Using the field (`UPDATED_OFFENSE_CATEGORY`), create a new field, `simplified_offense_derived`, that simplifies the many offense categories into broader buckets using the following process:\n",
    "\n",
    "First, combine all offenses beginning with \"Aggravated\" into a single category without that prefix (e.g., Aggravated Battery and Battery just becomes Battery)\n",
    "\n",
    "Then:\n",
    "- Combine all offenses with arson into a single arson category (`Arson`)\n",
    "- Combine all offenses with homicide into a single homicide category (`Homicide`)\n",
    "- Combine all offenses with vehicle/vehicular in the name into a single vehicle category (`Vehicle-related`)\n",
    "- Combine all offenses with battery in the name into a single battery category (`Battery`)\n",
    "\n",
    "Try to do so efficiently (e.g., write a function and apply to a column, rather than edit the variable repeatedly in separate line for each recoded offense)\n",
    "\n",
    "Print the difference between the # of unique offenses in the original `UPDATED_OFFENSE_CATEGORY` field and the # of unique offenses in your new `simplified_offense_derived` field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique offenses before simplification: 79\n",
      "Unique offenses after simplification: 65\n",
      "Difference: 14\n"
     ]
    }
   ],
   "source": [
    "# Build a function that first identifies aggravated charges, removes the prefix, and groups the four categories\n",
    "def simplify_offense_aggravated(offense):\n",
    "    if pd.isna(offense):\n",
    "        return np.nan\n",
    "    offense_lower = str(offense).lower().strip()\n",
    "    # Remove leading \"Aggravated\" (case-insensitive)\n",
    "    if offense_lower.startswith(\"aggravated \"):\n",
    "        offense_lower = offense_lower[len(\"aggravated \"):].strip()\n",
    "    if \"arson\" in offense_lower:\n",
    "        return \"Arson\"\n",
    "    elif \"homicide\" in offense_lower:\n",
    "        return \"Homicide\"\n",
    "    elif \"vehic\" in offense_lower:\n",
    "        return \"Vehicle-related\"\n",
    "    elif \"battery\" in offense_lower:\n",
    "        return \"Battery\"\n",
    "    else:\n",
    "        return offense_lower\n",
    "\n",
    "# Applying to a column\n",
    "df[\"simplified_offense_derived\"] = df[\"UPDATED_OFFENSE_CATEGORY\"].apply(simplify_offense_aggravated)\n",
    "\n",
    "# Show the difference between the number of unique offenses before and after simplification\n",
    "original_unique = df[\"UPDATED_OFFENSE_CATEGORY\"].nunique(dropna=False)\n",
    "simplified_unique = df[\"simplified_offense_derived\"].nunique(dropna=False)\n",
    "print(f\"Unique offenses before simplification: {original_unique}\")\n",
    "print(f\"Unique offenses after simplification: {simplified_unique}\")\n",
    "print(f\"Difference: {original_unique - simplified_unique}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Cleaning additional variables (10 points)\n",
    "\n",
    "Clean the following variables; make sure to retain the original variable in data and use the derived suffix so it's easier to pull these cleaned out variables later (e.g., `age_derived`) to indicate this was a transformation\n",
    "\n",
    "- Race: create True/false indicators for `is_black_derived` (Black only or mixed race with hispanic), Non-Black Hispanic, so either hispanic alone or white hispanic (`is_hisp_derived`), White non-hispanic (`is_white_derived`), or none of the above (`is_othereth_derived`)\n",
    "\n",
    "- Gender: create a boolean true/false indicator for `is_male_derived` (false is female, unknown, or other)\n",
    "\n",
    "- Age at incident: you notice outliers like 130-year olds. Winsorsize the top 0.01% of values to be equal to the 99.99th percentile value pre-winsorization. Call this `age_derived`\n",
    "\n",
    "- Create `sentenceymd_derived` that's a version of `SENTENCE_DATE` converted to datetime format. Also create a rounded version, `sentenceym_derived`, that's rounded down to the first day of the month (e.g., `1/5/2016` would become `1/1/2016` and `3/27/2018` would become `3/1/2018`)\n",
    "    - Hint: all timestamps are midnight so u can strip in conversion. For full credit, before converting, you notice that some of the years have been mistranscribed (e.g., 291X or 221X instead of 201X). Programatically fix those (eg 2914 -> 2014). Even after cleaning, there will still be some that are after the year 2021 that we'll filter out later. For partial credit, you can ignore the timestamps that cause errors and set errors = \"coerce\" within `pd.to_datetime()` to allow the conversion to proceed. \n",
    "\n",
    "- Sentencing judge: create an identifier (`judgeid_derived`) for each unique judge (`SENTENCE_JUDGE`) structured as judge_1, judge_2...., with the order determined by sorting the judges (will sort on fname then last). When finding unique judges, there are various duplicates we could weed out --- for now, just focus on (1) the different iterations of Doug/Douglas Simpson, (2) the different iterations of Shelley Sutker (who appears both with her maiden name and her hyphenated married name). \n",
    "     - Hint: due to mixed types, you may need to cast the `SENTENCE_JUDGE` var to a diff type to sort\n",
    "\n",
    "After finishing, print a random sample of 10 rows (data.sample(n = 10)) with the original and cleaned columns for the relevant variables to validate your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique values in RACE column:\n",
      "['ASIAN', 'American Indian', 'Asian', 'Biracial', 'Black', 'HISPANIC', 'Unknown', 'White', 'White [Hispanic or Latino]', 'White/Black [Hispanic or Latino]']\n"
     ]
    }
   ],
   "source": [
    "# Print all unique values of RACE column for inspection\n",
    "print(\"All unique values in RACE column:\")\n",
    "print(sorted(df[\"RACE\"].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race Indicators\n",
    "race_str = df[\"RACE\"].str.upper().fillna(\"\")\n",
    "\n",
    "df[\"is_black_derived\"] = (\n",
    "    race_str.isin([\"BLACK\"]) |\n",
    "    (race_str.str.contains(\"BLACK\") & race_str.str.contains(\"HISPANIC\"))\n",
    ")\n",
    "\n",
    "df[\"is_hisp_derived\"] = (\n",
    "    race_str.str.contains(\"HISPANIC\") | race_str.str.contains(\"LATINO\")\n",
    ") & ~df[\"is_black_derived\"]\n",
    "\n",
    "df[\"is_white_derived\"] = (\n",
    "    race_str.str.contains(\"WHITE\") &\n",
    "    ~race_str.str.contains(\"HISPANIC\") &\n",
    "    ~race_str.str.contains(\"LATINO\") &\n",
    "    ~df[\"is_black_derived\"]\n",
    ")\n",
    "\n",
    "df[\"is_othereth_derived\"] = ~(\n",
    "    df[\"is_black_derived\"] | df[\"is_hisp_derived\"] | df[\"is_white_derived\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeted examples for each race indicator:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>is_black_derived</th>\n",
       "      <th>is_hisp_derived</th>\n",
       "      <th>is_white_derived</th>\n",
       "      <th>is_othereth_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RACE  is_black_derived  is_hisp_derived  \\\n",
       "0                        Black              True            False   \n",
       "18  White [Hispanic or Latino]             False             True   \n",
       "26                       White             False            False   \n",
       "41                         NaN             False            False   \n",
       "\n",
       "    is_white_derived  is_othereth_derived  \n",
       "0              False                False  \n",
       "18             False                False  \n",
       "26              True                False  \n",
       "41             False                 True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Race indicator value counts:\n",
      "is_black_derived\n",
      "True     165661\n",
      "False     82485\n",
      "Name: count, dtype: int64\n",
      "\n",
      "is_hisp_derived\n",
      "False    204325\n",
      "True      43821\n",
      "Name: count, dtype: int64\n",
      "\n",
      "is_white_derived\n",
      "False    212785\n",
      "True      35361\n",
      "Name: count, dtype: int64\n",
      "\n",
      "is_othereth_derived\n",
      "False    244843\n",
      "True       3303\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output code for race indicators\n",
    "\n",
    "race_cols = [\"RACE\", \"is_black_derived\", \"is_hisp_derived\", \"is_white_derived\", \"is_othereth_derived\"]\n",
    "\n",
    "def show_race_examples(df):\n",
    "    # Find one example for each derived group\n",
    "    examples = []\n",
    "    # Black (True)\n",
    "    ex_black = df[df[\"is_black_derived\"]].head(1)\n",
    "    if not ex_black.empty:\n",
    "        examples.append(ex_black)\n",
    "    # Hispanic (True)\n",
    "    ex_hisp = df[df[\"is_hisp_derived\"]].head(1)\n",
    "    if not ex_hisp.empty:\n",
    "        examples.append(ex_hisp)\n",
    "    # White (True)\n",
    "    ex_white = df[df[\"is_white_derived\"]].head(1)\n",
    "    if not ex_white.empty:\n",
    "        examples.append(ex_white)\n",
    "    # Other (True)\n",
    "    ex_other = df[df[\"is_othereth_derived\"]].head(1)\n",
    "    if not ex_other.empty:\n",
    "        examples.append(ex_other)\n",
    "    # Concatenate and show\n",
    "    if examples:\n",
    "        display(pd.concat(examples)[race_cols])\n",
    "    else:\n",
    "        print(\"No examples found for the derived race indicators.\")\n",
    "\n",
    "print(\"Targeted examples for each race indicator:\")\n",
    "show_race_examples(df)\n",
    "\n",
    "print(\"\\nRace indicator value counts:\")\n",
    "for col in race_cols[1:]:\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MALE' 'FEMALE' nan 'MALE NAME, NO GENDER GIVEN' 'UNKNOWN GENDER'\n",
      " 'UNKNOWN']\n",
      "is_male_derived\n",
      "True     217610\n",
      "False     30536\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"GENDER\"].str.upper().unique())\n",
    "\n",
    "# Gender Indicator: only tue if MALE or MALE NAME\n",
    "# Others (including \"NO GENDER GIVEN\") as not male\n",
    "gender_upper = df[\"GENDER\"].str.upper().fillna(\"\")\n",
    "df[\"is_male_derived\"] = gender_upper.isin([\"MALE\", \"MALE NAME\"])\n",
    "print(df[\"is_male_derived\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    238359.000000\n",
      "mean         32.302611\n",
      "std          11.779161\n",
      "min          17.000000\n",
      "25%          23.000000\n",
      "50%          29.000000\n",
      "75%          40.000000\n",
      "max          81.000000\n",
      "Name: age_derived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Age at Incident Winsorization (Basically capping the 99.99%)\n",
    "age_col = \"AGE_AT_INCIDENT\"\n",
    "percentile_9999 = df[age_col].quantile(0.9999)\n",
    "df[\"age_derived\"] = df[age_col].clip(upper=percentile_9999)\n",
    "print(df[\"age_derived\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 05/01/2914 12:00:00 AM  -->  Fixed: 05/01/2014 12:00:00 AM\n",
      "Original: 12/31/2218 12:00:00 AM  -->  Fixed: 12/31/2018 12:00:00 AM\n",
      "Original: 01/01/2119 12:00:00 AM  -->  Fixed: 01/01/2019 12:00:00 AM\n",
      "Original: 06/15/2020 12:00:00 AM  -->  Fixed: 06/15/2020 12:00:00 AM\n",
      "Original: 07/20/2015 12:00:00 AM  -->  Fixed: 07/20/2015 12:00:00 AM\n",
      "Original: 03/10/2512 12:00:00 AM  -->  Fixed: 03/10/2012 12:00:00 AM\n",
      "Original: 03/10/3212 12:00:00 AM  -->  Fixed: 03/10/2012 12:00:00 AM\n",
      "Original: None  -->  Fixed: None\n",
      "Original: random text  -->  Fixed: random text\n"
     ]
    }
   ],
   "source": [
    "# Sentence Date Reformating to datetime\n",
    "\n",
    "# Function to fix mistranscribed years\n",
    "def fix_year(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return date_str\n",
    "\n",
    "    s = str(date_str).strip()\n",
    "    if not s:\n",
    "        return s\n",
    "\n",
    "    parts = s.split()\n",
    "    date_part = parts[0]\n",
    "    rest = \" \".join(parts[1:])\n",
    "\n",
    "    # Only handle slash dates like MM/DD/YYYY\n",
    "    if \"/\" not in date_part:\n",
    "        return s\n",
    "\n",
    "    d = date_part.split(\"/\")\n",
    "    if len(d) != 3:\n",
    "        return s\n",
    "\n",
    "    mm, dd, yyyy = d[0], d[1], d[2]\n",
    "\n",
    "    # Fix 4-digit years where digits are mistranscribed\n",
    "    # Pattern: first digit is 2 or 3, but not a valid 20XX year (i.e., 2nd digit makes it invalid)\n",
    "    if yyyy.isdigit() and len(yyyy) == 4:\n",
    "        year_int = int(yyyy)\n",
    "        # If year appears to be in future decades that don't exist yet\n",
    "        # Assume it should be 20XX where XX is the last two digits\n",
    "        if year_int > 2025 and year_int < 9999:\n",
    "            yyyy = \"20\" + yyyy[2:]\n",
    "\n",
    "    fixed_date = f\"{mm}/{dd}/{yyyy}\"\n",
    "    return f\"{fixed_date} {rest}\".strip()\n",
    "\n",
    "\n",
    "test_dates = [\n",
    "    \"05/01/2914 12:00:00 AM\",\n",
    "    \"12/31/2218 12:00:00 AM\",\n",
    "    \"01/01/2119 12:00:00 AM\",\n",
    "    \"06/15/2020 12:00:00 AM\",\n",
    "    \"07/20/2015 12:00:00 AM\",\n",
    "    \"03/10/2512 12:00:00 AM\",\n",
    "    \"03/10/3212 12:00:00 AM\",\n",
    "    None,\n",
    "    \"random text\"\n",
    "]\n",
    "\n",
    "# Print before and after for each test case\n",
    "for d in test_dates:\n",
    "    print(f\"Original: {d}  -->  Fixed: {fix_year(d)}\")\n",
    "\n",
    "# Apply the fix function and convert to datetime\n",
    "df[\"SENTENCE_DATE_cleaned\"] = df[\"SENTENCE_DATE\"].apply(fix_year)\n",
    "df[\"sentenceymd_derived\"] = pd.to_datetime(df[\"SENTENCE_DATE_cleaned\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Round down to first day of month\n",
    "df[\"sentenceym_derived\"] = df[\"sentenceymd_derived\"].dt.to_period(\"M\").dt.start_time\n",
    "\n",
    "# Drop column no longer needed since transferred to sentenceymd_derived\n",
    "df.drop(columns=[\"SENTENCE_DATE_cleaned\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doug/Douglas Simpson mapping:\n",
      "         SENTENCE_JUDGE judgeid_derived\n",
      "1115      Doug  Simpson        judge_71\n",
      "1621  Douglas J Simpson        judge_71\n",
      "\n",
      "Shelley Sutker variations mapping:\n",
      "             SENTENCE_JUDGE judgeid_derived\n",
      "131         Shelley  Sutker       judge_281\n",
      "142  Shelley  Sutker-Dermer       judge_281\n",
      "\n",
      "General sample of judge mappings:\n",
      "          SENTENCE_JUDGE judgeid_derived\n",
      "0          John  Mannion       judge_140\n",
      "4      Clayton Jay Crane        judge_41\n",
      "11        James L Rhodes       judge_114\n",
      "12       Thomas V Gainer       judge_312\n",
      "18          Kay M Hanlon       judge_163\n",
      "19      William J Kunkle       judge_333\n",
      "20         Evelyn B Clay        judge_84\n",
      "26  Timothy Joseph Joyce       judge_316\n",
      "27       Steven J Goebel       judge_289\n",
      "29        Carol M Howard        judge_32\n"
     ]
    }
   ],
   "source": [
    "# Judge ID Creation\n",
    "\n",
    "# Function to standardize judge names before creating mapping\n",
    "def standardize_judge(j):\n",
    "    if pd.isna(j):\n",
    "        return j\n",
    "    \n",
    "    j = str(j).strip().lower()\n",
    "\n",
    "    if j ==\"\":\n",
    "        return pd.NA\n",
    "    \n",
    "    if (\"simpson\" in j) and (\"doug\" in j or \"douglas\" in j):\n",
    "        return \"Douglas Simpson\"\n",
    "    if (\"sutker\" in j) and (\"shelley\" in j):\n",
    "        return \"Shelley Sutker\"\n",
    "    \n",
    "    return j.title()  # Capitalize names for consistency\n",
    "\n",
    "# Apply standardization\n",
    "df[\"judge_cleaned\"] = df[\"SENTENCE_JUDGE\"].astype(str).apply(standardize_judge)\n",
    "\n",
    "# Get unique judges, remove missing values and null values, and sort them\n",
    "unique_judges = df[\"judge_cleaned\"].dropna().unique()\n",
    "unique_judges_sorted = sorted(unique_judges)\n",
    "\n",
    "# Create a mapping from judge name to ID\n",
    "judge_mapping = {judge: f\"judge_{i+1}\" for i, judge in enumerate(unique_judges_sorted)}\n",
    "df[\"judgeid_derived\"] = df[\"judge_cleaned\"].map(judge_mapping)\n",
    "\n",
    "# Dropped column due to mapping on to judgeid_derived\n",
    "df.drop(columns=[\"judge_cleaned\"], inplace=True)\n",
    "\n",
    "# Show mapping for Doug/Douglas Simpson and Shelley Sutker variations\n",
    "simpson_mask = df[\"SENTENCE_JUDGE\"].astype(str).str.contains(\"Simpson\")\n",
    "sutker_mask = df[\"SENTENCE_JUDGE\"].astype(str).str.contains(\"Sutker\")\n",
    "\n",
    "print(\"Doug/Douglas Simpson mapping:\")\n",
    "print(df.loc[simpson_mask, [\"SENTENCE_JUDGE\", \"judgeid_derived\"]].drop_duplicates())\n",
    "\n",
    "print(\"\\nShelley Sutker variations mapping:\")\n",
    "print(df.loc[sutker_mask, [\"SENTENCE_JUDGE\", \"judgeid_derived\"]].drop_duplicates())\n",
    "\n",
    "print(\"\\nGeneral sample of judge mappings:\")\n",
    "print(df[[\"SENTENCE_JUDGE\", \"judgeid_derived\"]].drop_duplicates().head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample of 10 rows with original vs cleaned columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>is_black_derived</th>\n",
       "      <th>is_hisp_derived</th>\n",
       "      <th>is_white_derived</th>\n",
       "      <th>is_othereth_derived</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>is_male_derived</th>\n",
       "      <th>AGE_AT_INCIDENT</th>\n",
       "      <th>age_derived</th>\n",
       "      <th>SENTENCE_DATE</th>\n",
       "      <th>sentenceymd_derived</th>\n",
       "      <th>sentenceym_derived</th>\n",
       "      <th>SENTENCE_JUDGE</th>\n",
       "      <th>judgeid_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142698</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11/14/2014 12:00:00 AM</td>\n",
       "      <td>2014-11-14</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>Nicholas R Ford</td>\n",
       "      <td>judge_237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158821</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10/23/2017 12:00:00 AM</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>Kevin M Sheehan</td>\n",
       "      <td>judge_169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34334</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7/19/2011 12:00:00 AM</td>\n",
       "      <td>2011-07-19</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>Michael  Brown</td>\n",
       "      <td>judge_217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191085</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6/4/2018 12:00:00 AM</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>William H Hooks</td>\n",
       "      <td>judge_331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111801</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3/7/2014 12:00:00 AM</td>\n",
       "      <td>2014-03-07</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>Mary Margaret Brosnahan</td>\n",
       "      <td>judge_206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227468</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12/19/2018 12:00:00 AM</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Thomas J Hennelly</td>\n",
       "      <td>judge_303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5/12/2011 12:00:00 AM</td>\n",
       "      <td>2011-05-12</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>John T Doody</td>\n",
       "      <td>judge_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137169</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2/22/2016 12:00:00 AM</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>James Michael Obbish</td>\n",
       "      <td>judge_116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72496</th>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2/28/2013 12:00:00 AM</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>Lawrence Edward Flood</td>\n",
       "      <td>judge_179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142678</th>\n",
       "      <td>White [Hispanic or Latino]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11/20/2014 12:00:00 AM</td>\n",
       "      <td>2014-11-20</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>Thaddeus L Wilson</td>\n",
       "      <td>judge_298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              RACE  is_black_derived  is_hisp_derived  \\\n",
       "142698  White [Hispanic or Latino]             False             True   \n",
       "158821                       Black              True            False   \n",
       "34334   White [Hispanic or Latino]             False             True   \n",
       "191085  White [Hispanic or Latino]             False             True   \n",
       "111801                       Black              True            False   \n",
       "227468                       Black              True            False   \n",
       "18374                        Black              True            False   \n",
       "137169  White [Hispanic or Latino]             False             True   \n",
       "72496                        Black              True            False   \n",
       "142678  White [Hispanic or Latino]             False             True   \n",
       "\n",
       "        is_white_derived  is_othereth_derived  GENDER  is_male_derived  \\\n",
       "142698             False                False    Male             True   \n",
       "158821             False                False    Male             True   \n",
       "34334              False                False    Male             True   \n",
       "191085             False                False    Male             True   \n",
       "111801             False                False    Male             True   \n",
       "227468             False                False    Male             True   \n",
       "18374              False                False  Female            False   \n",
       "137169             False                False  Female            False   \n",
       "72496              False                False    Male             True   \n",
       "142678             False                False    Male             True   \n",
       "\n",
       "        AGE_AT_INCIDENT  age_derived           SENTENCE_DATE  \\\n",
       "142698             27.0         27.0  11/14/2014 12:00:00 AM   \n",
       "158821             28.0         28.0  10/23/2017 12:00:00 AM   \n",
       "34334              31.0         31.0   7/19/2011 12:00:00 AM   \n",
       "191085             33.0         33.0    6/4/2018 12:00:00 AM   \n",
       "111801             17.0         17.0    3/7/2014 12:00:00 AM   \n",
       "227468             43.0         43.0  12/19/2018 12:00:00 AM   \n",
       "18374              43.0         43.0   5/12/2011 12:00:00 AM   \n",
       "137169             35.0         35.0   2/22/2016 12:00:00 AM   \n",
       "72496              54.0         54.0   2/28/2013 12:00:00 AM   \n",
       "142678             49.0         49.0  11/20/2014 12:00:00 AM   \n",
       "\n",
       "       sentenceymd_derived sentenceym_derived           SENTENCE_JUDGE  \\\n",
       "142698          2014-11-14         2014-11-01          Nicholas R Ford   \n",
       "158821          2017-10-23         2017-10-01          Kevin M Sheehan   \n",
       "34334           2011-07-19         2011-07-01           Michael  Brown   \n",
       "191085          2018-06-04         2018-06-01          William H Hooks   \n",
       "111801          2014-03-07         2014-03-01  Mary Margaret Brosnahan   \n",
       "227468          2018-12-19         2018-12-01        Thomas J Hennelly   \n",
       "18374           2011-05-12         2011-05-01             John T Doody   \n",
       "137169          2016-02-22         2016-02-01     James Michael Obbish   \n",
       "72496           2013-02-28         2013-02-01    Lawrence Edward Flood   \n",
       "142678          2014-11-20         2014-11-01        Thaddeus L Wilson   \n",
       "\n",
       "       judgeid_derived  \n",
       "142698       judge_237  \n",
       "158821       judge_169  \n",
       "34334        judge_217  \n",
       "191085       judge_331  \n",
       "111801       judge_206  \n",
       "227468       judge_303  \n",
       "18374        judge_150  \n",
       "137169       judge_116  \n",
       "72496        judge_179  \n",
       "142678       judge_298  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the columns that are needed for validation\n",
    "validation_col = [\"RACE\", \"is_black_derived\", \"is_hisp_derived\", \"is_white_derived\", \"is_othereth_derived\", \n",
    "                  \"GENDER\", \"is_male_derived\", \n",
    "                  \"AGE_AT_INCIDENT\", \"age_derived\", \n",
    "                  \"SENTENCE_DATE\", \"sentenceymd_derived\", \"sentenceym_derived\",\n",
    "                  \"SENTENCE_JUDGE\", \"judgeid_derived\"]\n",
    "\n",
    "print(\"Random sample of 10 rows with original vs cleaned columns\")\n",
    "df.sample(n=10)[validation_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4: Subsetting rows to analytic dataset (5 points)\n",
    "\n",
    "You decide based on the above to simplify things in the following ways:\n",
    "    \n",
    "- Subset to cases where only one participant is charged, since cases with >1 participant might have complications like \n",
    "plea bargains/informing from other participants affecting the sentencing of the focal participant\n",
    "\n",
    "- To go from a participant-case level dataset, where each participant is repeated across charges tied to the case, to a participant-level dataset, where each participant has one charge, subset to a participant's primary charge and their current sentence (`PRIMARY_CHARGE_FLAG` is True and `CURRENT_SENTENCE_FLAG` is True). Double check that this worked by confirming there are no longer multiple charges for the same case-participant\n",
    "\n",
    "- Filter out observations where judge is nan or nonsensical (indicated by is.null or equal to FLOOD)\n",
    "\n",
    "- Subset to sentencing date between 01-01-2012 and 04-05-2021 (inclusive)\n",
    "\n",
    "After completing these steps, print the number of rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (248146, 52) \n",
      "\n",
      "After subsetting to single-participant cases. (216252, 52) \n",
      "\n",
      "After subsetting to primary charges with current sentences: (152900, 52) \n",
      "\n",
      "Max unique charges per case-participant after subsetting: 1\n",
      "Min unique charges per case-participant after subsetting: 1 \n",
      "\n",
      "Drop n/a judges: (152449, 52) \n",
      "\n",
      "Number of rows in analytic dataset after subsetting: 135165\n",
      "\n",
      "Sanity Check of Analytic Dataset:\n",
      "Unique CASE_PARTICIPANT_ID in analytic dataset: 135165\n",
      "Unique CASE_ID in analytic dataset: 135165\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame shape:\", df.shape, \"\\n\")\n",
    "# Subset cases where only 1 participant is charged\n",
    "single_participant_cases = participants_counts[participants_counts == 1].index\n",
    "df_analytic = df[df[\"CASE_ID\"].isin(single_participant_cases)].copy()\n",
    "print(\"After subsetting to single-participant cases.\", df_analytic.shape, \"\\n\")\n",
    "\n",
    "# Reduce to a participant-level dataset with only primary charges and current sentences\n",
    "focal = df_analytic[\"PRIMARY_CHARGE_FLAG\"] & df_analytic[\"CURRENT_SENTENCE_FLAG\"]\n",
    "df_analytic = df_analytic.loc[focal].copy()\n",
    "print(\"After subsetting to primary charges with current sentences:\", df_analytic.shape, \"\\n\")\n",
    "\n",
    "# Confirm no multiple charges for the same case-participant\n",
    "charges_per_case_participant = df_analytic.groupby([\"CASE_ID\", \"CASE_PARTICIPANT_ID\"])[\"CHARGE_ID\"].nunique()\n",
    "print(\"Max unique charges per case-participant after subsetting:\", charges_per_case_participant.max())\n",
    "print(\"Min unique charges per case-participant after subsetting:\", charges_per_case_participant.min(), \"\\n\")\n",
    "\n",
    "# Filter out observations where judge is nan or nonsensical\n",
    "j = df_analytic[\"SENTENCE_JUDGE\"]\n",
    "judge_ok = j.notna() & j.astype(str).str.strip().ne(\"\") & j.astype(str).str.strip().str.upper().ne(\"FLOOD\")\n",
    "df_analytic = df_analytic.loc[judge_ok].copy()\n",
    "\n",
    "print(\"Drop n/a judges:\", df_analytic.shape, \"\\n\")\n",
    "\n",
    "# Subset to sentencing date between 01-01-2012 and 04-05-2021 inclusive\n",
    "start_date = pd.Timestamp(\"2012-01-01\")\n",
    "end_date = pd.Timestamp(\"2021-04-05\")\n",
    "\n",
    "date_ok = df_analytic[\"sentenceymd_derived\"].between(start_date, end_date, inclusive=\"both\")\n",
    "df_analytic = df_analytic.loc[date_ok].copy()\n",
    "\n",
    "# Print number of rows after subsetting\n",
    "print(\"Number of rows in analytic dataset after subsetting:\", len(df_analytic))\n",
    "\n",
    "# Sanity Check\n",
    "print(\"\\nSanity Check of Analytic Dataset:\")\n",
    "\n",
    "print(\"Unique CASE_PARTICIPANT_ID in analytic dataset:\", df_analytic[\"CASE_PARTICIPANT_ID\"].nunique())\n",
    "print(\"Unique CASE_ID in analytic dataset:\", df_analytic[\"CASE_ID\"].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qss20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
